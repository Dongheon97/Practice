{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0ULhlUVUWbhd"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import numpy as np\n","from tqdm import tqdm\n","from IPython.display import HTML\n","from torch.utils.tensorboard import SummaryWriter\n","#from tensorboardX import SummaryWriter\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n","        self.fc1 = nn.Linear(2048, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","def client_update(client_model, optimizer, train_loader, epoch=5):\n","    model.train()\n","\n","    for e in range(epoch):\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            data, target = data.cuda(), target.cuda()\n","            optimizer.zero_grad()\n","            output = client_model(data)\n","            loss = F.nll_loss(output, target)\n","            loss.backward()\n","            optimizer.step()\n","    return loss.item()\n","\n","def server_aggregate(global_model, client_models):\n","    global_dict = global_model.state_dict()\n","    for k in global_dict.keys():\n","        global_dict[k] = torch.stack([client_models[i].state_dict()[k] \n","                                      for i in range(len(client_models))], 0).mean(0)\n","    global_model.load_state_dict(global_dict)\n","    for model in client_models:\n","        model.load_state_dict(global_model.state_dict())\n","\n","def test(global_model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.cuda(), target.cuda()\n","            output = global_model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    acc = correct / len(test_loader.dataset)\n","\n","    return test_loss, acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8oT_s9SDWyww"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bdI8hNzZWzct"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMISWk5uQbkHYfjKYkU8lFn","name":"FL_torch.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}