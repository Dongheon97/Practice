{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc9cd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11edccde",
   "metadata": {},
   "source": [
    "<h2>Model Construction for On-Device Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cbf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28\n",
    "\n",
    "class Model(tf.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(IMG_SIZE, IMG_SIZE), name='flatten'),\n",
    "        tf.keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
    "        tf.keras.layers.Dense(10, name='dense_2')\n",
    "    ])\n",
    "\n",
    "    self.model.compile(\n",
    "        optimizer='sgd',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "  # The `train` function takes a batch of input images and labels.\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),\n",
    "      tf.TensorSpec([None, 10], tf.float32),\n",
    "  ])\n",
    "  def train(self, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      prediction = self.model(x)\n",
    "      loss = self.model.loss(y, prediction)\n",
    "    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "    self.model.optimizer.apply_gradients(\n",
    "        zip(gradients, self.model.trainable_variables))\n",
    "    result = {\"loss\": loss}\n",
    "    return result\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),\n",
    "  ])\n",
    "  def infer(self, x):\n",
    "    logits = self.model(x)\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"output\": probabilities,\n",
    "        \"logits\": logits\n",
    "    }\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def save(self, checkpoint_path):\n",
    "    tensor_names = [weight.name for weight in self.model.weights]\n",
    "    tensors_to_save = [weight.read_value() for weight in self.model.weights]\n",
    "    tf.raw_ops.Save(\n",
    "        filename=checkpoint_path, tensor_names=tensor_names,\n",
    "        data=tensors_to_save, name='save')\n",
    "    return {\n",
    "        \"checkpoint_path\": checkpoint_path\n",
    "    }\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def restore(self, checkpoint_path):\n",
    "    restored_tensors = {}\n",
    "    for var in self.model.weights:\n",
    "      restored = tf.raw_ops.Restore(\n",
    "          file_pattern=checkpoint_path, tensor_name=var.name, dt=var.dtype,\n",
    "          name='restore')\n",
    "      var.assign(restored)\n",
    "      restored_tensors[var.name] = restored\n",
    "    return restored_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3640f",
   "metadata": {},
   "source": [
    "<h2>Fashion MNIST Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2343722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "40960/29515 [=========================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 31s 1us/step\n",
      "26435584/26421880 [==============================] - 31s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 4s 1us/step\n",
      "4431872/4422102 [==============================] - 4s 1us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3f30a",
   "metadata": {},
   "source": [
    "<h2>Preprocess</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860fe786",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images / 255.0).astype(np.float32)\n",
    "test_images = (test_images / 255.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788f527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993be23b",
   "metadata": {},
   "source": [
    "<h2>Train Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31235d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 22:33:02.472474: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 22:33:02.472937: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-09 22:33:02.677030: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 22:33:02.677468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10 epochs\n",
      "  loss: 0.424\n",
      "Finished 20 epochs\n",
      "  loss: 0.370\n",
      "Finished 30 epochs\n",
      "  loss: 0.335\n",
      "Finished 40 epochs\n",
      "  loss: 0.316\n",
      "Finished 50 epochs\n",
      "  loss: 0.302\n",
      "Finished 60 epochs\n",
      "  loss: 0.288\n",
      "Finished 70 epochs\n",
      "  loss: 0.275\n",
      "Finished 80 epochs\n",
      "  loss: 0.266\n",
      "Finished 90 epochs\n",
      "  loss: 0.258\n",
      "Finished 100 epochs\n",
      "  loss: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 22:37:12.532785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'checkpoint_path': <tf.Tensor: shape=(), dtype=string, numpy=b'/tmp/model.ckpt'>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "epochs = np.arange(1, NUM_EPOCHS + 1, 1)\n",
    "losses = np.zeros([NUM_EPOCHS])\n",
    "m = Model()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "  for x,y in train_ds:\n",
    "    result = m.train(x, y)\n",
    "\n",
    "  losses[i] = result['loss']\n",
    "  if (i + 1) % 10 == 0:\n",
    "    print(f\"Finished {i+1} epochs\")\n",
    "    print(f\"  loss: {losses[i]:.3f}\")\n",
    "\n",
    "# Save the trained weights to a checkpoint.\n",
    "m.save('/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32459a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, losses, label='Pre-training')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [Cross Entropy]')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9697531",
   "metadata": {},
   "source": [
    "<h2>Convert to TfLite Format </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9f0286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 22:37:55.740628: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_181250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_181278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2022-01-09 22:37:56.012759: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
      "2022-01-09 22:37:56.012772: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
      "2022-01-09 22:37:56.012775: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:372] Ignored change_concat_input_ranges.\n",
      "2022-01-09 22:37:56.014196: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: saved_model\n",
      "2022-01-09 22:37:56.015213: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-01-09 22:37:56.015218: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: saved_model\n",
      "2022-01-09 22:37:56.017906: I tensorflow/cc/saved_model/loader.cc:210] Restoring SavedModel bundle.\n",
      "2022-01-09 22:37:56.034398: I tensorflow/cc/saved_model/loader.cc:194] Running initialization op on SavedModel bundle at path: saved_model\n",
      "2022-01-09 22:37:56.044196: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 29998 microseconds.\n",
      "2022-01-09 22:37:56.074356: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-01-09 22:37:56.129656: W tensorflow/compiler/mlir/lite/flatbuffer_expWARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "ort.cc:1891] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexReluGrad, FlexRestore, FlexSave\n",
      "Details:\n",
      "\ttf.ReluGrad(tensor<?x128xf32>, tensor<?x128xf32>) -> (tensor<?x128xf32>) : {device = \"\"}\n",
      "\ttf.Restore(tensor<!tf_type.string>, tensor<!tf_type.string>) -> (tensor<10xf32>) : {device = \"\", preferred_shard = -1 : i64}\n",
      "\ttf.Restore(tensor<!tf_type.string>, tensor<!tf_type.string>) -> (tensor<128x10xf32>) : {device = \"\", preferred_shard = -1 : i64}\n",
      "\ttf.Restore(tensor<!tf_type.string>, tensor<!tf_type.string>) -> (tensor<128xf32>) : {device = \"\", preferred_shard = -1 : i64}\n",
      "\ttf.Restore(tensor<!tf_type.string>, tensor<!tf_type.string>) -> (tensor<784x128xf32>) : {device = \"\", preferred_shard = -1 : i64}\n",
      "\ttf.Save(tensor<!tf_type.string>, tensor<4x!tf_type.string>, tensor<784x128xf32>, tensor<128xf32>, tensor<128x10xf32>, tensor<10xf32>) -> () : {device = \"\"}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "SAVED_MODEL_DIR = \"saved_model\"\n",
    "\n",
    "tf.saved_model.save(\n",
    "    m,\n",
    "    SAVED_MODEL_DIR,\n",
    "    signatures={\n",
    "        'train':\n",
    "            m.train.get_concrete_function(),\n",
    "        'infer':\n",
    "            m.infer.get_concrete_function(),\n",
    "        'save':\n",
    "            m.save.get_concrete_function(),\n",
    "        'restore':\n",
    "            m.restore.get_concrete_function(),\n",
    "    })\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "converter.experimental_enable_resource_variables = True\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c01c7",
   "metadata": {},
   "source": [
    "<h2>Tflite Signiture</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ffc012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "2022-01-09 22:40:04.447935: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-09 22:40:04.447984: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 17 nodes with 0 partitions.\n",
      "\n",
      "2022-01-09 22:40:04.452323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "infer = interpreter.get_signature_runner(\"infer\")\n",
    "\n",
    "# Compare Original with TfLite\n",
    "logits_original = m.infer(x=train_images[:1])['logits'][0]\n",
    "logits_lite = infer(x=train_images[:1])['logits'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7515d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
